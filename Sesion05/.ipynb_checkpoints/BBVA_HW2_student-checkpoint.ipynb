{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8SM-ZxE0FyQq"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "# Figures plotted inside the notebook\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# High quality figures\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79wf4V1sDUCy"
   },
   "outputs": [],
   "source": [
    "## Load NLTK Modules\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "punctuation = string.punctuation\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer  = WordNetLemmatizer()\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snowball = SnowballStemmer('english')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords   = set(nltk.corpus.stopwords.words('english'))\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MrVS0PuFzHo"
   },
   "source": [
    "# Reviews de la base de datos YELP academic\n",
    "\n",
    "En este homework vamos a trabajar con el [Yelp_academic_dataset](https://www.kaggle.com/yelp-dataset/yelp-dataset) que como sabemos contiene revisiones de negocios y establecimientos en 11 áreas metropolitanas de 4 países recogidas de usuarios del servicio Yelp. \n",
    "\n",
    "A diferencia de en la sesión de introducción donde ya usasteis este dataset  con la información de los negocios, aquí nos vamos a centrar en la información de las *reviews* y vamos a predecir el *rating* asociado a cada *review* a partir del contenido textual de estas *reviews*. Además, para facilitar el procesado de los datos, ya que el dataset original contine millones de *reviews*, hemos hecho una seleccion de unas 3500 *reviews* con las que trabajar en este homework.\n",
    "\n",
    "A lo largo del notebook se le pedirá que resuelva diferentes ejercicios, junto con la resolución de cada uno, por favor, **comente los resultados obtenidos**. Cuando realice cualquier elección de diseño, por favor, justifiquela adecuadamente. Todo ello se valorará de cara a la evaluación de la práctica.\n",
    "\n",
    "La siguiente celda de código carga el fichero que hemos preparado para este homework y separa las variables de texto con las reviews (que seran nuestras observaciones de entrada) de las etiquetas o variable objetivo del problema que serán las `stars`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joh9AwjWFyMP"
   },
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv(\"http://www.tsc.uc3m.es/~vanessa/data_notebooks/yelp/yelp_review_red.csv.zip\")\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rPBRiVxiGL3E"
   },
   "outputs": [],
   "source": [
    "reviews=list(reviews_df['text'])\n",
    "print(len(reviews))\n",
    "# Get labels\n",
    "y = reviews_df['stars']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMDJqCvQpwkh"
   },
   "source": [
    "# Ejercicio 1. Preprocesado de texto (2 ptos)\n",
    "\n",
    "Aplique el pipeline estandar visto en la sesión de NLP (tokenización, homogeneización y limpieza) para el preprocesado de las reviews.\n",
    "\n",
    "Nota: de este preprocesado elimine el *stemming* y aplique solo la lematización para obtener palabras completas que podamos analizar y utilizar más adelante.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ULCauebHJMe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEFFORp9JekG"
   },
   "source": [
    "# Ejercicio 2. Vectorización de la información textual (2 ptos)\n",
    "\n",
    "A partir del contenido preprocesado de las reviews, genere una representación vectorial para cada review. Para esta representación utilice:\n",
    "1. BoW\n",
    "2. TF-IDF\n",
    "\n",
    "Como para generar estas representaciones necesita definir un diccionario, antes de generar la representación vectorial, analice el diccionario generado y, con el criterio o criterios que considere más adecuados, limite su tamaño a 1000 términos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_1jf8j7q8lo"
   },
   "source": [
    "## 2.1 Creacción del diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3NU6ugmvJGIF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxfXwqBVNJaO"
   },
   "source": [
    "#<SOL>\n",
    "Para limpiar del diccionario: elegir los 1000 términos más relevantes tenemos en cuenta:\n",
    "* No hay palabras que están en más 1500-2000 documentos (de 3500) no hace falta fijar `no_above` \n",
    "* Para que se quede como mucho con 1000, n_keep = 1000\n",
    "* Ya no es necesario fijar no_below porque n_keep va a poner ese corte para quedarse con 1000\n",
    "\n",
    "#</SOL>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOIld8-rJspL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmgZ6XqIPyPo"
   },
   "source": [
    "## 2.2 Representación BoW\n",
    "Obtenga la representación BoW de las reviews preprocesadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMCbXu8jPw_1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4m9JkbE5QyY-"
   },
   "source": [
    "## 2.3 Representación TF-IDF\n",
    "Obtenga la representación TF-IDF de las reviews preprocesadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIFdahc_QyK7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "syyBFObsROcR"
   },
   "source": [
    "## 2.4 Conversión a matrices sparse\n",
    "\n",
    "Use la función `corpus2csc` para convertir las representaciones BoW y TF-IDF a matrices sparse con las que poder trabajar en las siguientes secciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXI3sDStP5nE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tT0SCpL8RQ_a"
   },
   "source": [
    "# Ejercicio 3. Modelos de predicción con BoW y TFIDF  (2 ptos)\n",
    "\n",
    "Utilice las representaciones vectoriales obtenidas anteriormente para predecir la puntuación asociada a cada review. Para esta predicción utilice y compare un regresor tipo k-NN (con la distancia coseno) y un modelo *Ridge Regression* lineal.\n",
    "\n",
    "Para el entrenamiento y evalaución de estos modelos considere:\n",
    "* 40% de los datos para entrenar y 60% para testear\n",
    "* Aplique un proceso de CV con 5 fold para validar adecuadamente los parámetros libres de cada modelo\n",
    "* Evalúe las prestaciones finales en términos de $R^2$.\n",
    "\n",
    "Además, no se olvide de normalizar los datos \n",
    "si lo considera necesario, en cuyo caso justifique la normalización aplicada.\n",
    "\n",
    "Por último, compare y comente los resultados obtenidos. ¿Qué representación de los datos da mejores resultados? ¿Qué regresor funciona mejor? ¿A qué cree que puede deberse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pe4-s59cIGe6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWWGjaDVR8EG"
   },
   "source": [
    "**K-NN y *Ridge Regression* con BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LlZpA8t0StaH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZrgW9J7Si9U"
   },
   "source": [
    "**K-NN y *Ridge Regression* con TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NergNMIWTX08"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JF81E8gpaPFi"
   },
   "source": [
    "# Ejercicio 4. *Embeddings* (2 ptos)\n",
    "\n",
    "En este ejercicio vamos a utilizar algunos de los *embeddings* que hemos visto para reducir la dimensión de las representaciones vectoriales obtenidas anteriomente. En concreto, vamos a usar tres tipos de *embeddings* en esta sección:\n",
    "* *Principal Component Analysis* (PCA)\n",
    "* *Spectral Embedding*\n",
    "* *Embedding con K-means*\n",
    "\n",
    "Para simplificar este análisis, a partir de ahora solo vamos a trabajar con la representación TF-IDF. Así que obtenga para los vectores TF-IDF el *embedding* asociado y utilícelo para ver las prestaciones que nos daría el modelo de *ridge regression* lineal. Obtenga estas prestaciones para un *embedding* de tamaño 2, 10, 25, 50 y 100 y analice cómo influye el tamaño del *embedding* en las prestaciones del regresor.\n",
    "\n",
    "Por último, para el *embedding* de dimensión 2 haga una representación del mismo, donde cada *review* será un punto en este espacio bidimensional y asígnele diferentes colores según las puntuaciones que tenga asociadas (por ejemplo, las *reviews* con puntuación 1 las visualizamos en rojo, las *reviews* con puntuación 2 las visualizamos en azul, ...). \n",
    "\n",
    "Finalmente, analice los resultados obtenidos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBDmh5H6aRSW"
   },
   "source": [
    "## 4.1 *Embeddings* con PCA\n",
    "\n",
    "El método PCA de sklearn no trabaja con matrices sparse, así que para poder aplicar esta transformación de los datos, tendrá que comenzar transformando la representación sparse TF-IDF a una representación densa (para ello puede usar el método `.toarray()` de las matrices sparse)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLjS6DUn_wyy"
   },
   "source": [
    "## 4.2 *Spectral Embeddings* \n",
    "Evalúe aquí las pretaciones proporcionadas por un *Spectral Embedding* usando como matriz de afinidad un kernel [chi_square](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.chi2_kernel.html) definido como:\n",
    "\n",
    "$$k(x, y) = \\exp \\left(-\\gamma \\sum_{d=1}^D \\frac{(x_d - y_d)^2}{x_d + y_d}\\right)$$\n",
    "con parámetro $\\gamma$ igual a 1 (valor por defecto). Este kernel suele usarse para medir distancias entre histogramas por lo que es una buena opción para medir distancias entre representaciones TF-IDF.\n",
    "\n",
    "Recuerde que tendrá que calcular esta proyección de manera conjunta sobre los datos de entrenamiento y test y luego volver a separar los datasets. Además, tenga en cuenta que el kernel chi_square no funciona con datos  *sparse*, así que deberá volver transformar los datos a formato denso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqaW9HB_3qxS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwiWK4YN0IM3"
   },
   "source": [
    "## 4.2 *Embeddings* con K-means\n",
    "\n",
    "El método K-means sí admite la representación *sparse* de los datos, así que no hace falta que en este caso convierta sus datos a formato denso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-YQRFeH0IM5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yd_n1Aai4o8Y"
   },
   "source": [
    "# Ejercicio 5. *Embeddings* con *Word2Vec* (2 ptos)\n",
    "\n",
    "En esta última sección vamos a obtener la representación *Word2Vec* para obtener un *embedding* de las palabras de nuestro corpus de *reviews* y luego utilizaremos esta representación para predecir la puntuación de cada *review*.\n",
    "\n",
    "Para ello, vaya resolviendo los siguientes apartados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGkkXP1R2eGU"
   },
   "source": [
    "## 5.1 *Word2Vec* de las palabras del corpus de *reviews*\n",
    "\n",
    "Comience entrenando una red neuronal del tipo word2vec para obtener un *embedding* de tamaño 200 con un tamaño de ventana de 5 y eliminando las palabras que aparecen en menos de 20 documentos.\n",
    "\n",
    "Extraiga del modelo el *embedding* aprendido y use el algoritmo t-SNE para representar este  *embedding* en dos dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "azQPjubp1JRA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQADXfS9ySUF"
   },
   "source": [
    "## 5.2 Análisis del  *Word2Vec* \n",
    "\n",
    "Utilice el método `.most_similar` del word2vec que acaba de entrenar para encontrar las palabras más similares a los términos `breakfast`, `great` y  `wrong`. ¿Cree que el modelo ha sido capaz de aprender la semantica del cospus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nd1aw5cj4bTw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2t9EkmoXWlko"
   },
   "source": [
    "## 5.3 Representación de las *reviews* a partir del *Word2Vec* \n",
    "\n",
    "En esta sección vamos a representar cada documento con el `word2vec` promedio de las palabras de cada *review*. Para facilitar este cálculo las siguientes celdas de código generan una lista con el vocabulario de las *reviews* y otra lista con el vocabulario del *embedding*. A partir de ellas:\n",
    "1. Construya una matriz con los embeddings para las palabras del vocabulario de las *reviews*. Llame a esta matriz `embeddings_vocab`\n",
    "2. Genere un *embedding* por *review* como el producto escalar del BoW de esa review y `embeddings_vocab`. De este modo estará calculando un promedio ponderado de los *embeddings* para las palabras en esa review.\n",
    "3. Normalice el *embedding* de cada documento a norma 1 para compensar el efecto de los documentos más largos frente a los documentos con menos palabras. Para ello puede usar la función `normalize_dense_vector` que le damos a continuación.\n",
    "\n",
    "Si lo desea, con ayuda del t-SNE, puede representar estos embeddings en un espacio bidimensional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYOhkDeuVQXm"
   },
   "outputs": [],
   "source": [
    "def normalize_dense_vector(s):\n",
    "  norm1 = np.linalg.norm(s, axis =1)\n",
    "  norm1[norm1==0] =1\n",
    "  return (s.T/norm1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1G6Abf-0ZN1f"
   },
   "outputs": [],
   "source": [
    "# Vocabulario de las reviews\n",
    "vocab_reviews = list(D.values()) \n",
    "print(len(vocab_reviews))\n",
    "print(vocab_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l49D81fEaAFQ"
   },
   "outputs": [],
   "source": [
    "# Vocabulario del embedding\n",
    "vocab_emb = list(model.wv.vocab)\n",
    "print(len(vocab_emb))\n",
    "print(vocab_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jy5Dqt6haiJg"
   },
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7iYh5R86Gpq"
   },
   "source": [
    "## 5.4 Estimación de los *ratings* a partir de la representación  *Word2Vec* \n",
    "\n",
    "Utilice la representación anterior de cada *review* para estimar su *rating* mediante un modelo *Ridge Regresion* lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLOYfObTeFG_"
   },
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ok1sIMh083FX"
   },
   "source": [
    "# Ejercicio 6 (EXTRA). Utilización de modelos *Word2Vec* preentrenados \n",
    "\n",
    "Repita el ejercicio anterior, pero utilizando el *Word2Vec* preentrenado de Google News. La siguiente celda de código carga este modelo para su uso y extrae los *embeddings*. Tenga en cuenta que este modelo preentrenado no tiene porque incluir todas las palabras del vocabulario de las *reviews*, así que para las palabras que no estén, simplemente no las tenga en cuenta para generar el *embedding* promedio de la *review*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8bWvbzkPeNxH"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkN6mn2DV0rc"
   },
   "outputs": [],
   "source": [
    "# get embeddings\n",
    "embeddings = wv.vectors \n",
    "\n",
    "# Vocabulario del embedding\n",
    "vocab_emb = list(wv.vocab)\n",
    "print(len(vocab_emb))\n",
    "print(vocab_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wgth7hJM_t2B"
   },
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDv880eD16_W"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
